{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## PROJET FINAL: Detecting Wagon Maintenance Tripsâ€‹"
      ],
      "metadata": {
        "id": "G3rrhfOKcDEt"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kTycpnYDLzg7"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.ticker as ticker\n",
        "import seaborn as sns\n",
        "from datetime import datetime, timedelta"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "A_Zmo1T8L8q6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "file = '/content/drive/MyDrive/dataset_2.csv'"
      ],
      "metadata": {
        "id": "D4eLPUhWMJhz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = pd.read_csv(file)\n",
        "dataset"
      ],
      "metadata": {
        "id": "irhsLv78MPz5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset.columns"
      ],
      "metadata": {
        "id": "S2c4Pvj7MWh2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset.info()"
      ],
      "metadata": {
        "id": "EqXyNczqMh98"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(dataset.isna().sum()/dataset.shape[0]).sort_values(ascending=True)"
      ],
      "metadata": {
        "id": "Fzz64cvTMk4B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = dataset.drop([\"Unnamed: 0\", \"date\", \"Latitude\", \"Longitude\", \"wagon_number\"], axis=1)\n",
        "dataset"
      ],
      "metadata": {
        "id": "EeHqojMEMt9Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "index_with_nan = dataset.index[dataset.isnull().any(axis=1)]"
      ],
      "metadata": {
        "id": "6wlhX2TDsj6-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset.drop(index_with_nan,0, inplace=True)"
      ],
      "metadata": {
        "id": "KF292uo6ssZp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset.head()"
      ],
      "metadata": {
        "id": "UXl4MACus64L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Examen de la colonne target"
      ],
      "metadata": {
        "id": "Hv2uHfuzM3E-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset['target'].value_counts(normalize=True)"
      ],
      "metadata": {
        "id": "6B4bHPmSM4S-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Separate target variable Y from features X\n",
        "print(\"Separating labels from features...\")\n",
        "Y = dataset.loc[:,\"target\"]\n",
        "X = dataset.drop(\"target\", axis = 1) # Keeping all columns\n",
        "print(\"...Done.\")\n",
        "print(Y.head())\n",
        "print()\n",
        "print(X.head())"
      ],
      "metadata": {
        "id": "MpAMgWWVNDQr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "print(\"Dividing into train and test sets...\")\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=0)\n",
        "print(\"...Done.\")\n",
        "print()"
      ],
      "metadata": {
        "id": "qg0EaHRHNxVY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.impute import SimpleImputer         \n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder"
      ],
      "metadata": {
        "id": "R-2F7cRhOBlH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_imputer = SimpleImputer(strategy=\"median\")            # missing values will be replaced by columns' median\n",
        "num_imputer.fit_transform(X_train.iloc[:, 1:])"
      ],
      "metadata": {
        "id": "mHCyIVbEWX6d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create pipeline for numeric features\n",
        "num_features = [1,2,3,4,5] # Names of numeric columns in X_train/X_test\n",
        "num_transformer = Pipeline(steps=[\n",
        "    \n",
        "    ('scaler', StandardScaler())\n",
        "])"
      ],
      "metadata": {
        "id": "3pBKQx2kOxS0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import OneHotEncoder"
      ],
      "metadata": {
        "id": "9sGeQSg0WwIH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score"
      ],
      "metadata": {
        "id": "j5wcoB-FW9-b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.compose import ColumnTransformer"
      ],
      "metadata": {
        "id": "QqxM_VZ_RO44"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Use ColumnTranformer to make a preprocessor object that describes all the treatments to be done\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        (\"num_transformer\", num_transformer, num_features)\n",
        "        \n",
        "    ])\n",
        "\n",
        "# Preprocessings on train set\n",
        "X_train = preprocessor.fit_transform(X_train)\n",
        "X_train[:5] # Numpy syntax to display 5 first lines\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "HyibP8M3Rs6o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Encode target variable Y\n",
        "encoder = LabelEncoder()\n",
        "Y_train = encoder.fit_transform(Y_train.squeeze())\n",
        "Y_train"
      ],
      "metadata": {
        "id": "PxZ1rhg0UG0d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## TRANING PHASE"
      ],
      "metadata": {
        "id": "tUJv29xUiy_0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train model\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "classifier = RandomForestClassifier(random_state=0)\n",
        "classifier.fit(X_train, Y_train)\n",
        "classifier.score(X_train, Y_train)"
      ],
      "metadata": {
        "id": "n9KUleBgivNj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Predictions "
      ],
      "metadata": {
        "id": "xivfsZgH8YxI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Predictions on training set\n",
        "print(\"Predictions on training set...\")\n",
        "Y_train_pred = classifier.predict(X_train)\n",
        "print(\"...Done.\")\n",
        "print(Y_train_pred[0:5])\n",
        "print()"
      ],
      "metadata": {
        "id": "GtJOosMm8ab6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocessings on test set\n",
        "X_test = preprocessor.fit_transform(X_test)\n",
        "X_test[:5]"
      ],
      "metadata": {
        "id": "BJzYp1H6uH_x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Encode target variable Y\n",
        "encoder = LabelEncoder()\n",
        "Y_test = encoder.fit_transform(Y_test.squeeze())\n",
        "Y_test"
      ],
      "metadata": {
        "id": "vb2UpsfyvRgW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "classifier.score(X_test, Y_test)"
      ],
      "metadata": {
        "id": "lZqnLHedvqzG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Predictions on test set\n",
        "print(\"Predictions on test set...\")\n",
        "Y_test_pred = classifier.predict(X_test)\n",
        "print(\"...Done.\")\n",
        "print(Y_test_pred[0:5])\n",
        "print()"
      ],
      "metadata": {
        "id": "5OIwSQSe80lu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Performance Evaluation"
      ],
      "metadata": {
        "id": "zArkaQis9FDn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Print scores\n",
        "print(\"Accuracy on training set : \", accuracy_score(Y_train, Y_train_pred)) # Always pass true label first, and predictions in second position\n",
        "print(\"Accuracy on test set : \", accuracy_score(Y_test, Y_test_pred))"
      ],
      "metadata": {
        "id": "JWUaTlRP9D0_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import f1_score, confusion_matrix, classification_report\n",
        "from sklearn.model_selection import learning_curve"
      ],
      "metadata": {
        "id": "Z4idZuY-8_0O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluation(model):\n",
        "    \n",
        "    model.fit(X_train, Y_train)\n",
        "    ypred = classifier.predict(X_test)\n",
        "\n",
        "    print(ypred)\n",
        "    \n",
        "    print(confusion_matrix(Y_test, ypred))\n",
        "    print(classification_report(Y_test, ypred))\n",
        "    \n",
        "    N, train_score, val_score = learning_curve(model, X_train, Y_train,\n",
        "                                              cv=4, scoring='f1',\n",
        "                                               train_sizes=np.linspace(0.1, 1, 10))\n",
        "    \n",
        "    \n",
        "    plt.figure(figsize=(12, 8))\n",
        "    plt.plot(N, train_score.mean(axis=1), label='train score')\n",
        "    plt.plot(N, val_score.mean(axis=1), label='validation score')\n",
        "    plt.legend()"
      ],
      "metadata": {
        "id": "9j6Z-tc8mvWJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "evaluation(classifier)"
      ],
      "metadata": {
        "id": "nQpmLHj9oIpS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.feature_selection import SelectKBest, f_classif\n",
        "from sklearn.preprocessing import PolynomialFeatures, StandardScaler"
      ],
      "metadata": {
        "id": "G5Lspn54lT65"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preprocessor = make_pipeline(PolynomialFeatures(2, include_bias=False), SelectKBest(f_classif, k=10))"
      ],
      "metadata": {
        "id": "CDA7xpK_lbHD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "RandomForest = make_pipeline(preprocessor, RandomForestClassifier(random_state=0))\n",
        "AdaBoost = make_pipeline(preprocessor, AdaBoostClassifier(random_state=0))\n",
        "SVM = make_pipeline(preprocessor, StandardScaler(), SVC(random_state=0))\n",
        "KNN = make_pipeline(preprocessor, StandardScaler(), KNeighborsClassifier())"
      ],
      "metadata": {
        "id": "9vtvYiyUldW1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dict_of_models = {'RandomForest': RandomForest,\n",
        "                  'AdaBoost' : AdaBoost,\n",
        "                  'SVM': SVM,\n",
        "                  'KNN': KNN\n",
        "                 }"
      ],
      "metadata": {
        "id": "dke6dZ4Wlhs_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for name, model in dict_of_models.items():\n",
        "    print(name)\n",
        "    evaluation(model)"
      ],
      "metadata": {
        "id": "4k3XnoSLlpHW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## OPTIMISATION"
      ],
      "metadata": {
        "id": "bPnW6cVUh9Ld"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
        "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.feature_selection import SelectKBest, f_classif\n",
        "from sklearn.preprocessing import PolynomialFeatures, StandardScaler"
      ],
      "metadata": {
        "id": "bUaemKWTiChK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "SVM"
      ],
      "metadata": {
        "id": "VCQ6WKKPtNRP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hyper_params = {'svc__gamma':[1e-3, 1e-4, 0.0005],\n",
        "                'svc__C':[1, 10, 100, 1000, 3000], \n",
        "               'pipeline__polynomialfeatures__degree':[2, 3],\n",
        "               'pipeline__selectkbest__k': range(45, 60)}"
      ],
      "metadata": {
        "id": "sPBQMr2niLNW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "grid = RandomizedSearchCV(SVM, hyper_params, scoring='recall', cv=4,\n",
        "                          n_iter=10)\n",
        "\n",
        "grid.fit(X_train, Y_train)\n",
        "\n",
        "print(grid.best_params_)\n",
        "\n",
        "y_pred = grid.predict(X_test)\n",
        "\n",
        "print(classification_report(Y_test, y_pred))"
      ],
      "metadata": {
        "id": "tkcCtICPiMN8"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}